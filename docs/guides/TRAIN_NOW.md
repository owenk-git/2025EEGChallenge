# Train Now - Quick Reference

## ğŸ¯ Simple Commands (Use These!)

### 1. Quick Test (5 minutes)
```bash
python train.py -c 1 -o -m --max 5 -e 3
```
**Tests**: Pipeline works correctly
**Data**: Mini subset (~10 subjects)

---

### 2. Full Training - Challenge 1 (12-24 hours)
```bash
python train.py -c 1 -o -e 100
```
**Trains**: ALL 3,387 subjects from R1-R11 + NC
**Output**: `checkpoints/c1_best.pth`

---

### 3. Full Training - Challenge 2 (12-24 hours)
```bash
python train.py -c 2 -o -e 100
```
**Trains**: ALL 3,387 subjects from R1-R11 + NC
**Output**: `checkpoints/c2_best.pth`

---

### 4. Create Submission
```bash
python create_submission.py \
  --model_c1 checkpoints/c1_best.pth \
  --model_c2 checkpoints/c2_best.pth
```
**Output**: `YYYYMMDD_HHMM_trained_submission.zip`

---

### 5. Submit!
Upload ZIP to: https://www.codabench.org/competitions/9975/

---

## âœ… What You Get

### Automatic Features:
- âœ… Streams ALL 3,387 subjects from S3 (R1-R11 + NC)
- âœ… No download required
- âœ… Behavioral targets auto-loaded
- âœ… Subject-wise validation split (prevents data leakage)
- âœ… Saves best model based on validation NRMSE
- âœ… Comprehensive metrics logged
- âœ… Predictions saved for analysis

### During Training You'll See:
```
ğŸ“¦ Loading EEGChallengeDataset
   Task: contrastChangeDetection
   Release: all (ALL RELEASES - 3,387 subjects)  â† âœ… Check!
   Mini: False ğŸŒ (FULL dataset)                 â† âœ… Check!
âœ… Loaded 67231 recordings
   Unique subjects: 3387                         â† âœ… Check!

ğŸ§  Creating model for Challenge 1
   Parameters: 156,873

ğŸ“ˆ Training Progress:
Epoch 1/100
  Train loss: 0.1234
  Val NRMSE: 1.0234 â­ (Competition Metric)
  Val Pearson: 0.4567
  Val RÂ²: 0.3456
  âœ… Best model saved! (improved: âˆ â†’ 1.0234)
```

---

## ğŸš¨ Common Issues

### Issue: "Unique subjects: 10"
**Problem**: Using mini dataset
**Fix**: Remove `-m` flag

```bash
# âŒ Wrong:
python train.py -c 1 -o -m -e 100

# âœ… Correct:
python train.py -c 1 -o -e 100
```

---

### Issue: "eegdash not installed"
**Problem**: Missing packages
**Fix**: Install packages

```bash
pip install eegdash braindecode s3fs boto3 mne pandas torch
```

---

### Issue: "Only loading one release"
**Problem**: Using old custom S3 streaming
**Fix**: Use official dataset with `-o` flag

```bash
# âŒ Wrong (old custom S3):
python train.py -c 1 -d s3://... -s -e 100

# âœ… Correct (official dataset):
python train.py -c 1 -o -e 100
```

---

## ğŸ“Š Expected Performance

### After Quick Test (5 min, mini data):
- **NRMSE**: ~1.5-2.0 (random, not meaningful)
- **Purpose**: Verify pipeline works

### After 100 Subjects (2 hours):
- **NRMSE**: ~1.2-1.4
- **Purpose**: First working baseline

### After ALL Subjects (12-24 hours):
- **NRMSE**: ~1.0-1.2
- **Target**: Beat 1.14 (current best)
- **Goal**: Reach 0.95-1.00 (near SOTA)

---

## ğŸ¯ Training Timeline

### Today (Quick Validation)
1. Test pipeline: `python train.py -c 1 -o -m --max 5 -e 3` (5 min)
2. Verify it works âœ…

### Tonight (Baseline)
1. Train C1: `python train.py -c 1 -o --max 100 -e 50` (2 hrs)
2. Train C2: `python train.py -c 2 -o --max 100 -e 50` (2 hrs)
3. Submit â†’ Should beat 1.14 âœ…

### Tomorrow (Full Training)
1. Train C1: `python train.py -c 1 -o -e 100` (12-24 hrs)
2. Train C2: `python train.py -c 2 -o -e 100` (12-24 hrs)
3. Submit â†’ Aim for <1.0 âœ…

### Next Week (Optimization)
1. Try exploration experiments (--num 1-10)
2. Ensemble multiple models
3. Add inference strategies
4. Beat SOTA (0.978)! ğŸ†

---

## ğŸ’¡ Pro Tips

### Tip 1: Use GPU Selector
```bash
CUDA_VISIBLE_DEVICES=0 python train.py -c 1 -o -e 100
```

### Tip 2: Run Both Challenges in Parallel
```bash
# Terminal 1
CUDA_VISIBLE_DEVICES=0 python train.py -c 1 -o -e 100

# Terminal 2
CUDA_VISIBLE_DEVICES=1 python train.py -c 2 -o -e 100
```

### Tip 3: Monitor Progress
Training prints progress every epoch:
- Watch for improving validation NRMSE
- Best model saved automatically
- Check `checkpoints/c1_best.pth` exists

### Tip 4: Save Different Experiments
```bash
# Experiment 1: Baseline
python train.py -c 1 -o -e 100 --num 1

# Experiment 2: High dropout
python train.py -c 1 -o -e 100 --num 2 --drop 0.4

# Compare results in experiments/experiments.json
```

---

## ğŸ“ Output Files

After training, you'll have:

```
BCI/
â”œâ”€â”€ checkpoints/
â”‚   â”œâ”€â”€ c1_best.pth              â† Best C1 model (use for submission)
â”‚   â”œâ”€â”€ c2_best.pth              â† Best C2 model (use for submission)
â”‚   â”œâ”€â”€ c1_epoch10.pth           â† Checkpoint at epoch 10
â”‚   â””â”€â”€ c2_epoch10.pth           â† Checkpoint at epoch 10
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ c1_results.pt            â† Predictions, metrics, config
â”‚   â””â”€â”€ c2_results.pt
â”‚
â”œâ”€â”€ experiments/
â”‚   â””â”€â”€ experiments.json         â† All experiments logged
â”‚
â””â”€â”€ data_cache/                  â† Small metadata cache (~MB)
    â””â”€â”€ eeg_challenge/
```

---

## ğŸš€ Ready to Train?

### Step 1: Quick test (5 min)
```bash
python train.py -c 1 -o -m --max 5 -e 3
```

### Step 2: If test passes, run full training
```bash
python train.py -c 1 -o -e 100
python train.py -c 2 -o -e 100
```

### Step 3: Create submission
```bash
python create_submission.py \
  --model_c1 checkpoints/c1_best.pth \
  --model_c2 checkpoints/c2_best.pth
```

### Step 4: Submit and beat 1.14! ğŸ¯

---

**That's it! Three simple commands to train on ALL competition data.** ğŸš€
